{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ Triumvirate }} provides algorithms for computing clustering statistics in\n",
    "both Fourier and configuration space and in both local and global\n",
    "plane-parallel approximations (see ['Background'](../background.rst) for\n",
    "details).\n",
    "\n",
    "The usage of these measurement algorithms is all very similar, so as\n",
    "an example we will consider the bispectrum measurement below, and briefly\n",
    "mention the differences for other measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triumvirate.threept import compute_bispec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of inputs for measurements:\n",
    "- catalogue objects (as {py:class}`~triumvirate.catalogue.ParticleCatalogue`;\n",
    "  see the ['Particle Catalogue'](./Catalogue.ipynb) tutorial);\n",
    "- measurement parameters (as {py:class}`~triumvirate.parameters.ParameterSet`\n",
    "  or passed/overriden by keyword arguments; see the\n",
    "  ['Parameter Set'](./Parameters.ipynb) tutorial);\n",
    "- optional logger (as {py:class}`logging.Logger`; see the\n",
    "  ['Customised Logger'](./Logger.ipynb) tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse `trv_logger`, `parameter_set`, `binning` and `catalogue` created\n",
    "in tutorials ['Customised Logger'](./Logger.ipynb),\n",
    "['Parameter Set'](./Parameters.ipynb), ['Binnig Scheme'](./Binning.ipynb) and\n",
    "['Particle Catalogue'](./Catalogue.ipynb) as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:44:39 (+00:00:00) STAT C++] Parameters validated.\n"
     ]
    }
   ],
   "source": [
    "from triumvirate.logger import setup_logger\n",
    "from triumvirate.parameters import ParameterSet\n",
    "from triumvirate.dataobjs import Binning\n",
    "\n",
    "# Demo logger\n",
    "trv_logger = setup_logger()\n",
    "\n",
    "# Demo parameter set\n",
    "try:\n",
    "    parameter_set = ParameterSet(param_filepath=\"parameter_template.yml\")\n",
    "except OSError:\n",
    "    from triumvirate.parameters import fetch_paramset_template\n",
    "\n",
    "    parameter_dict = fetch_paramset_template('dict')\n",
    "\n",
    "    for ax_name in ['x', 'y', 'z']:\n",
    "        parameter_dict['boxsize'][ax_name] = 1000.\n",
    "        parameter_dict['ngrid'][ax_name] = 128\n",
    "\n",
    "    parameter_dict.update({\n",
    "        'catalogue_type': 'sim',\n",
    "        'statistic_type': 'bispec',\n",
    "        'degrees'       : {'ell1': 0, 'ell2': 0, 'ELL': 0},\n",
    "        'range'         : [0.005, 0.105],\n",
    "        'num_bins'      : 10,\n",
    "    })\n",
    "\n",
    "    parameter_set = ParameterSet(param_dict=parameter_dict)\n",
    "\n",
    "# Demo binning\n",
    "binning = Binning('fourier', 'lin', bin_min=0.005, bin_max=0.105, num_bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we have used ``nbodykit`` to produce three types of\n",
    "mock catalogues:\n",
    "\n",
    "- The first is a simulation-like log-normal catalogue `catalogue_sim`\n",
    "  in a cubic box of size $L = 1000.\\,h^{-1}\\,\\mathrm{Mpc}$ with number density\n",
    "  $\\bar{n} = 5 \\times 10^{-4} \\,h^3\\,\\mathrm{Mpc}^{-3}$. The input cosmological\n",
    "  parameters are $h = 0.6736, \\Omega_{\\mathrm{CDM},0} = 0.2645, \n",
    "  \\Omega_{\\mathrm{b},0} = 0.04930, A_s = 2.083 \\times 10^{-9}$ and\n",
    "  $n_s = 0.9649$, and the linear power spectrum at redshift $z = 1.$ with\n",
    "  linear tracer bias $b_1 = 2$ is used.\n",
    "\n",
    "- The second is a survey-like catalogue `catalogue_survey` based on\n",
    "  the simulation-like one, with the catalogue cut to the inscribing sphere of\n",
    "  radius $L/2$ inside the cubic box.\n",
    "\n",
    "- The third is a uniform random catalogue `catalogue_rand` with\n",
    "  number density $5 \\bar{n}$ in the same spherical volume as\n",
    "  the survey-like one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nbodykit.cosmology import Cosmology\n",
    "\n",
    "# Cosmology, matter power spectrum and bias at given redshift\n",
    "cosmo = Cosmology(\n",
    "    h=0.6736, Omega0_b=0.04930, Omega0_cdm=0.2645, A_s=2.083e-09, n_s=0.9649\n",
    ")\n",
    "redshift = 1.\n",
    "bias = 2.\n",
    "\n",
    "# Catalogue properties\n",
    "density = 5.e-4\n",
    "boxsize = 1000.\n",
    "\n",
    "# Catalogue selectors\n",
    "def cut_to_sphere(coords, boxsize):\n",
    "    return np.less_equal(np.sqrt(np.sum(coords**2, axis=-1)), boxsize/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create simulation-like catalogue, or load if existing.\n",
    "catalogue_sim_filepath = \"mock_catalogue_sim.dat\"\n",
    "\n",
    "try:\n",
    "    catalogue_sim = np.loadtxt(\n",
    "        catalogue_sim_filepath,\n",
    "        dtype=[(axis, np.float64) for axis in ['x', 'y', 'z']]\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    from nbodykit.lab import LinearPower, LogNormalCatalog\n",
    "    powspec = LinearPower(cosmo, redshift)\n",
    "    catalogue_sim = LogNormalCatalog(\n",
    "        powspec, density, boxsize, bias=bias, Nmesh=256, seed=42\n",
    "    )\n",
    "    catalogue_sim['Position'] -= boxsize/2.\n",
    "    np.savetxt(catalogue_sim_filepath, catalogue_sim['Position'].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create survey-like catalogue.\n",
    "try:\n",
    "    catalogue_survey = catalogue_sim[\n",
    "        cut_to_sphere(catalogue_sim['Position'], boxsize).compute()\n",
    "    ]\n",
    "except (IndexError, ValueError):\n",
    "    catalogue_survey = catalogue_sim[\n",
    "        cut_to_sphere(\n",
    "            catalogue_sim[['x', 'y', 'z']]\n",
    "            .view(np.float64).reshape(len(catalogue_sim), 3),\n",
    "            boxsize\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create random catalogue, or load if existing.\n",
    "catalogue_rand_filepath = \"mock_catalogue_rand.dat\"\n",
    "\n",
    "try:\n",
    "    catalogue_rand = np.loadtxt(\n",
    "        catalogue_rand_filepath,\n",
    "        dtype=[(axis, np.float64) for axis in ['x', 'y', 'z']]\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    from nbodykit.lab import UniformCatalog\n",
    "    catalogue_rand = UniformCatalog(5*density, boxsize, seed=42)\n",
    "    catalogue_rand['Position'] -= boxsize/2.\n",
    "    catalogue_rand = catalogue_rand[\n",
    "        cut_to_sphere(catalogue_rand['Position'], boxsize).compute()\n",
    "    ]\n",
    "    np.savetxt(catalogue_rand_filepath, catalogue_rand['Position'].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:45:07 (+00:00:27) INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2023-02-23 23:45:07 (+00:00:27) INFO] NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from triumvirate.catalogue import ParticleCatalogue\n",
    "\n",
    "warnings.filterwarnings('ignore', message=\".*'nz' field.*\")\n",
    "\n",
    "catalogue_sim = ParticleCatalogue(\n",
    "    *[catalogue_sim[coord_axis] for coord_axis in ['x', 'y', 'z']]\n",
    ")\n",
    "catalogue_survey = ParticleCatalogue(\n",
    "    *[catalogue_survey[coord_axis] for coord_axis in ['x', 'y', 'z']],\n",
    "    nz=density\n",
    ")\n",
    "catalogue_rand = ParticleCatalogue(\n",
    "    *[catalogue_rand[coord_axis] for coord_axis in ['x', 'y', 'z']],\n",
    "    nz=density\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having specified all the inputs, measurements can be made by simply passing\n",
    "them as arguments to the relevant function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:45:09 (+00:00:29) INFO] Parameter set have been initialised.\n",
      "[2023-02-23 23:45:09 (+00:00:29) STAT C++] Parameters validated.\n",
      "[2023-02-23 23:45:09 (+00:00:29) INFO] Binning has been initialised.\n",
      "[2023-02-23 23:45:09 (+00:00:29) INFO] Lines of sight have been initialised.\n",
      "[2023-02-23 23:45:10 (+00:00:30) INFO] Catalogues have been aligned.\n",
      "[2023-02-23 23:45:10 (+00:00:30) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-23 23:45:10 (+00:00:30) INFO C++] Catalogue loaded: 259444 particles with total sample weights 259444.000 (source=extdata).\n",
      "[2023-02-23 23:45:10 (+00:00:31) INFO C++] Extents of particle coordinates: {'x': (2.438, 998.884), 'y': (0.879, 998.351), 'z': (0.364, 998.843)} (source=extdata).\n",
      "[2023-02-23 23:45:12 (+00:00:32) INFO C++] Catalogue loaded: 1308287 particles with total sample weights 1308287.000 (source=extdata).\n",
      "[2023-02-23 23:45:12 (+00:00:32) INFO C++] Extents of particle coordinates: {'x': (0.604, 999.396), 'y': (0.630, 999.370), 'z': (0.426, 999.574)} (source=extdata).\n",
      "[2023-02-23 23:45:12 (+00:00:32) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-23 23:45:12 (+00:00:32) INFO] Alpha contrast: 1.983082e-01.\n",
      "[2023-02-23 23:45:14 (+00:00:34) INFO] Normalisation factors: 1.541759e+01 (used), 2.562281e+00 (alternative).\n",
      "[2023-02-23 23:45:14 (+00:00:34) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-23 23:45:18 (+00:00:39) STAT C++] Computing bispectrum from paired survey-type catalogues...\n",
      "[2023-02-23 23:46:25 (+00:01:45) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-23 23:46:25 (+00:01:45) STAT C++] Bispectrum term at orders (m1, m2, M) = (0, 0, 0) computed.\n",
      "[2023-02-23 23:46:25 (+00:01:46) STAT C++] ... computed bispectrum from paired survey-type catalogues.\n"
     ]
    }
   ],
   "source": [
    "results = compute_bispec(\n",
    "    catalogue_survey, catalogue_rand,\n",
    "    paramset=parameter_set,\n",
    "    logger=trv_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case above, the lines of sight are computed automatically, but one could\n",
    "supply external data arrays as replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:46:26 (+00:01:46) INFO] Parameter set have been initialised.\n",
      "[2023-02-23 23:46:26 (+00:01:46) STAT C++] Parameters validated.\n",
      "[2023-02-23 23:46:26 (+00:01:46) INFO] Binning has been initialised.\n",
      "[2023-02-23 23:46:26 (+00:01:46) INFO] Lines of sight have been initialised.\n",
      "[2023-02-23 23:46:26 (+00:01:46) INFO] Catalogues have been aligned.\n",
      "[2023-02-23 23:46:26 (+00:01:46) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-23 23:46:26 (+00:01:46) INFO C++] Catalogue loaded: 259444 particles with total sample weights 259444.000 (source=extdata).\n",
      "[2023-02-23 23:46:26 (+00:01:46) INFO C++] Extents of particle coordinates: {'x': (2.438, 998.884), 'y': (0.879, 998.351), 'z': (0.364, 998.843)} (source=extdata).\n",
      "[2023-02-23 23:46:27 (+00:01:47) INFO C++] Catalogue loaded: 1308287 particles with total sample weights 1308287.000 (source=extdata).\n",
      "[2023-02-23 23:46:27 (+00:01:47) INFO C++] Extents of particle coordinates: {'x': (0.604, 999.396), 'y': (0.630, 999.370), 'z': (0.426, 999.574)} (source=extdata).\n",
      "[2023-02-23 23:46:27 (+00:01:47) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-23 23:46:27 (+00:01:47) INFO] Alpha contrast: 1.983082e-01.\n",
      "[2023-02-23 23:46:28 (+00:01:48) INFO] Normalisation factors: 1.541759e+01 (used), 2.562281e+00 (alternative).\n",
      "[2023-02-23 23:46:28 (+00:01:48) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-23 23:47:39 (+00:02:59) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-23 23:46:32 (+00:01:52) STAT C++] Computing bispectrum from paired survey-type catalogues...\n",
      "[2023-02-23 23:47:39 (+00:02:59) STAT C++] Bispectrum term at orders (m1, m2, M) = (0, 0, 0) computed.\n",
      "[2023-02-23 23:47:39 (+00:02:59) STAT C++] ... computed bispectrum from paired survey-type catalogues.\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "results = compute_bispec(\n",
    "    catalogue_survey, catalogue_rand,\n",
    "    los_data=np.ones((len(catalogue_survey), 3)),\n",
    "    los_rand=np.ones((len(catalogue_rand), 3)),\n",
    "    paramset=parameter_set,\n",
    "    logger=trv_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also override `paramset` (which may be unset as shown in the example\n",
    "below) by passing the relevant keyword arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:47:39 (+00:02:59) INFO] Validating parameters... (entering C++)\n",
      "[2023-02-23 23:47:39 (+00:02:59) INFO] ... validated parameters. (exited C++)\n",
      "[2023-02-23 23:47:39 (+00:02:59) STAT C++] Parameters validated.\n",
      "[2023-02-23 23:47:39 (+00:02:59) INFO] Parameter set have been initialised.\n",
      "[2023-02-23 23:47:39 (+00:02:59) INFO] Binning has been initialised.\n",
      "[2023-02-23 23:47:40 (+00:03:00) INFO] Lines of sight have been initialised.\n",
      "[2023-02-23 23:47:40 (+00:03:00) INFO] Catalogues have been aligned.\n",
      "[2023-02-23 23:47:40 (+00:03:00) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-23 23:47:40 (+00:03:00) INFO C++] Catalogue loaded: 259444 particles with total sample weights 259444.000 (source=extdata).\n",
      "[2023-02-23 23:47:40 (+00:03:00) INFO C++] Extents of particle coordinates: {'x': (2.438, 998.884), 'y': (0.879, 998.351), 'z': (0.364, 998.843)} (source=extdata).\n",
      "[2023-02-23 23:47:41 (+00:03:02) INFO C++] Catalogue loaded: 1308287 particles with total sample weights 1308287.000 (source=extdata).\n",
      "[2023-02-23 23:47:41 (+00:03:01) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-23 23:47:41 (+00:03:02) INFO C++] Extents of particle coordinates: {'x': (0.604, 999.396), 'y': (0.630, 999.370), 'z': (0.426, 999.574)} (source=extdata).\n",
      "[2023-02-23 23:47:41 (+00:03:01) INFO] Alpha contrast: 1.983082e-01.\n",
      "[2023-02-23 23:47:42 (+00:03:02) INFO] Normalisation factors: 1.541759e+01 (used), 1.480691e+01 (alternative).\n",
      "[2023-02-23 23:47:42 (+00:03:02) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-23 23:47:45 (+00:03:06) STAT C++] Computing bispectrum from paired survey-type catalogues...\n",
      "[2023-02-23 23:47:53 (+00:03:13) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-23 23:47:49 (+00:03:09) STAT C++] Bispectrum term at orders (m1, m2, M) = (-1, 1, 0) computed.\n",
      "[2023-02-23 23:47:51 (+00:03:11) STAT C++] Bispectrum term at orders (m1, m2, M) = (0, 0, 0) computed.\n",
      "[2023-02-23 23:47:53 (+00:03:14) STAT C++] Bispectrum term at orders (m1, m2, M) = (1, -1, 0) computed.\n",
      "[2023-02-23 23:47:53 (+00:03:14) STAT C++] ... computed bispectrum from paired survey-type catalogues.\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "# import warnings\n",
    "warnings.filterwarnings('ignore', message=\".*default values are unchanged.*\")\n",
    "\n",
    "results = compute_bispec(\n",
    "    catalogue_survey, catalogue_rand,\n",
    "    degrees=(1, 1, 0),\n",
    "    binning=binning,\n",
    "    form='full',\n",
    "    idx_bin=5,\n",
    "    sampling_params={\n",
    "        'assignment': 'cic',\n",
    "        'boxsize': [1000.,]*3,\n",
    "        'ngrid': [64,]*3\n",
    "    },\n",
    "    logger=trv_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other measurement algorithms, the syntax is very similar except for a few\n",
    "minor differences:\n",
    "\n",
    "- For two-point clustering statistics, the argument corresponding to `degrees`\n",
    "  above is `degree` as there is only a single multipole degree. The arguments\n",
    "  `form` and `idx_bin` do not apply.\n",
    "\n",
    "- For global plane-parallel measurements, no random catalogue is required.\n",
    "\n",
    "- For window function measurements, only the random catalogue is required.\n",
    "\n",
    "For full details, please consult the API reference\n",
    "({py:mod}`~triumvirate.twopt` and {py:mod}`~triumvirate.threept`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned measurement results are dictionaries containing the\n",
    "raw statistic (key with suffix ``_raw``) without shot noise subtraction,\n",
    "the shot noise (key with suffix ``_shot``), the bin centres for each\n",
    "coordinate dimension (key with suffix ``bin``), the average/effectuve bin\n",
    "coordinates (key with suffix ``eff``), and the number of contributing modes\n",
    "in each bin (key ``'nmodes'``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bk_raw': array([-6.15401315e+08-3.19482081e-07j,  2.40744325e+08+1.72304943e-07j,\n",
      "       -2.84005114e+08-9.51266872e-08j, -1.06997676e+08-1.25639021e-07j,\n",
      "        1.94789754e+07+1.21151913e-08j,  8.29519632e+07+2.01581333e-08j,\n",
      "       -4.53112276e+06+5.02556083e-08j, -1.06546658e+08-3.58968631e-08j,\n",
      "       -6.84846274e+07-1.52561668e-08j, -1.14891079e+08+1.61535884e-08j]),\n",
      " 'bk_shot': array([ -5212454.33669118+8.88525628e-11j,\n",
      "        -8944908.7000952 -5.25045373e-11j,\n",
      "       -15387868.92505237+3.95731958e-11j,\n",
      "       -17045970.3545955 +1.09983928e-11j,\n",
      "       -21370062.6083337 +3.75538914e-11j,\n",
      "       -13373351.39063533-6.27183791e-11j,\n",
      "       -19646302.2498707 +9.65720444e-11j,\n",
      "       -16373587.0472606 +6.97114100e-11j,\n",
      "       -14739949.24948343+6.86204187e-11j,\n",
      "       -12282473.18290978+4.97694435e-11j]),\n",
      " 'k1bin': array([0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06]),\n",
      " 'k1eff': array([0.06040971, 0.06040971, 0.06040971, 0.06040971, 0.06040971,\n",
      "       0.06040971, 0.06040971, 0.06040971, 0.06040971, 0.06040971]),\n",
      " 'k2bin': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ]),\n",
      " 'k2eff': array([0.01149964, 0.02047114, 0.03052422, 0.04062536, 0.05033379,\n",
      "       0.06040971, 0.07034279, 0.08025683, 0.09014322, 0.10008191]),\n",
      " 'nmodes': array([  56,  194,  488,  812, 1250, 1896, 2426, 3272, 4016, 5138])}\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each algorithmic function for different measurements, if one sets\n",
    "``save='.txt'`` or ``save='.npz'``, the results as a dictionary will be\n",
    "automatically saved to a file in either ``.txt`` or ``.npz`` format.\n",
    "\n",
    "If the `paramset` argument is set to a\n",
    "{py:class}`~triumvirate.parameters.ParameterSet` object, the output directory\n",
    "will be ``paramset['directories']['measurements']``, and the string\n",
    "``paramset['tags']['output']`` will be appended to the file name before\n",
    "the extension suffix. An empty output directory string points to the\n",
    "current working directory. This is demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:47:54 (+00:03:14) INFO] Parameter set have been initialised.\n",
      "[2023-02-23 23:47:54 (+00:03:14) STAT C++] Parameters validated.\n",
      "[2023-02-23 23:47:54 (+00:03:14) INFO] Binning has been initialised.\n",
      "[2023-02-23 23:47:54 (+00:03:14) STAT C++] Parameters validated.\n",
      "[2023-02-23 23:47:54 (+00:03:14) INFO] Catalogue box has been periodised.\n",
      "[2023-02-23 23:47:54 (+00:03:14) INFO] Inserted missing 'nz' field based on particle count and boxsize.\n",
      "[2023-02-23 23:47:54 (+00:03:14) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-23 23:47:54 (+00:03:15) INFO C++] Catalogue loaded: 499214 particles with total sample weights 499214.000 (source=extdata).\n",
      "[2023-02-23 23:47:54 (+00:03:15) INFO C++] Extents of particle coordinates: {'x': (0.000, 1000.000), 'y': (0.000, 999.996), 'z': (0.001, 999.997)} (source=extdata).\n",
      "[2023-02-23 23:47:54 (+00:03:15) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-23 23:47:55 (+00:03:15) INFO] Normalisation factors: 4.012606e-03 (used), 4.283253e-04 (alternative).\n",
      "[2023-02-23 23:47:55 (+00:03:15) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-23 23:47:55 (+00:00:01) STAT C++] Computing power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-23 23:47:57 (+00:00:03) STAT C++] ... computed power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-23 23:47:57 (+00:03:18) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-23 23:47:57 (+00:03:18) INFO] Measurements saved to pk0_demo.txt.\n"
     ]
    }
   ],
   "source": [
    "from triumvirate.twopt import compute_powspec_in_gpp_box\n",
    "\n",
    "# DEMO\n",
    "parameter_set.update(tags={'output': '_demo'})\n",
    "\n",
    "results = compute_powspec_in_gpp_box(\n",
    "    catalogue_sim,\n",
    "    degree=0, paramset=parameter_set,\n",
    "    save='.txt', logger=trv_logger\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the output measurement file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Catalogue source: extdata\n",
      "# Catalogue size: 499214 particles of total weight 499214.000\n",
      "# Catalogue particle extents: ([0.000, 1000.000], [0.000, 999.996], [0.001, 999.997])\n",
      "# Box size: (1000.000, 1000.000, 1000.000)\n",
      "# Box alignment: centre\n",
      "# Mesh number: (256, 256, 256)\n",
      "# Mesh assignment and interlacing: tsc, false\n",
      "# Normalisation factor: 4.012605716e-03 (particle-based, used), 4.283253172e-04 (mesh-based, alternative)\n",
      "# [0] k_cen, [1] k_eff, [2] nmodes, [3] Re{pk0_raw}, [4] Im{pk0_raw}, [5] Re{pk0_shot}, [6] Im{pk0_shot}\n",
      "1.000000000e-02\t1.149964290e-02\t        56\t 3.160453651e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "2.000000000e-02\t2.047114034e-02\t       194\t 3.881278667e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "3.000000000e-02\t3.052421724e-02\t       488\t 2.746447398e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "4.000000000e-02\t4.062536317e-02\t       812\t 2.298579911e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "5.000000000e-02\t5.033378732e-02\t      1250\t 2.007403810e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "6.000000000e-02\t6.040971138e-02\t      1896\t 1.820389832e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "7.000000000e-02\t7.034278912e-02\t      2426\t 1.563758701e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "8.000000000e-02\t8.025683499e-02\t      3272\t 1.336556120e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "9.000000000e-02\t9.014322302e-02\t      4016\t 1.174654406e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "1.000000000e-01\t1.000819060e-01\t      5138\t 1.017407496e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "with open(\"pk0_demo.txt\", 'r') as results_file:\n",
    "    print(results_file.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a header with summary information about the input parameters and\n",
    "data have also be included in the saved file.\n",
    "\n",
    "Similarly, for the ``.npz`` output file, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-23 23:49:22 (+00:04:42) INFO] Parameter set have been initialised.\n",
      "[2023-02-23 23:49:22 (+00:04:42) STAT C++] Parameters validated.\n",
      "[2023-02-23 23:49:22 (+00:04:42) INFO] Binning has been initialised.\n",
      "[2023-02-23 23:49:22 (+00:04:42) INFO] Catalogue box has been periodised.\n",
      "[2023-02-23 23:49:22 (+00:04:42) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-23 23:49:23 (+00:04:43) INFO C++] Catalogue loaded: 499214 particles with total sample weights 499214.000 (source=extdata).\n",
      "[2023-02-23 23:49:23 (+00:04:43) INFO C++] Extents of particle coordinates: {'x': (0.000, 1000.000), 'y': (0.000, 999.996), 'z': (0.001, 999.997)} (source=extdata).\n",
      "[2023-02-23 23:49:23 (+00:04:43) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-23 23:49:23 (+00:04:43) INFO] Normalisation factors: 4.012606e-03 (used), 4.283253e-04 (alternative).\n",
      "[2023-02-23 23:49:23 (+00:04:43) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-23 23:49:23 (+00:01:29) STAT C++] Computing power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-23 23:49:27 (+00:04:47) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-23 23:49:26 (+00:01:32) STAT C++] ... computed power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-23 23:49:27 (+00:04:47) INFO] Measurements saved to pk0_demo.npz.\n"
     ]
    }
   ],
   "source": [
    "results = compute_powspec_in_gpp_box(\n",
    "    catalogue_sim,\n",
    "    degree=0, paramset=parameter_set,\n",
    "    save='.npz', logger=trv_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue source: extdata\n",
      "Catalogue size: 499214 particles of total weight 499214.000\n",
      "Catalogue particle extents: ([0.000, 1000.000], [0.000, 999.996], [0.001, 999.997])\n",
      "Box size: (1000.000, 1000.000, 1000.000)\n",
      "Box alignment: centre\n",
      "Mesh number: (256, 256, 256)\n",
      "Mesh assignment and interlacing: tsc, false\n",
      "Normalisation factor: 4.012605716e-03 (particle-based, used), 4.283253172e-04 (mesh-based, alternative)\n",
      "[0] k_cen, [1] k_eff, [2] nmodes, [3] Re{pk0_raw}, [4] Im{pk0_raw}, [5] Re{pk0_shot}, [6] Im{pk0_shot}\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "with np.load(\"pk0_demo.npz\", allow_pickle=True) as results_file:\n",
    "    print(results_file['header'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a7a1cba6a5ad1075172442d744886e76565787fe92f2df44113e5c941b518c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
