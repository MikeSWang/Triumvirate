{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Measurements"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{ Triumvirate }} provides algorithms for computing clustering statistics in\n",
    "both Fourier and configuration space and in both local and global\n",
    "plane-parallel approximations (see ['Background'](../background.rst) for\n",
    "details).\n",
    "\n",
    "The usage of these measurement algorithms is all very similar, so as\n",
    "an example we will mainly consider the bispectrum measurement below, and\n",
    "briefly mention the differences for other measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triumvirate.threept import compute_bispec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of inputs for measurements:\n",
    "- catalogue objects (as {py:class}`~triumvirate.catalogue.ParticleCatalogue`;\n",
    "  see also ['Particle Catalogue'](./Catalogue.ipynb));\n",
    "- measurement parameters (as {py:class}`~triumvirate.parameters.ParameterSet`\n",
    "  or passed/overriden by keyword arguments; see also\n",
    "  ['Parameter Set'](./Parameters.ipynb));\n",
    "- optional logger (as {py:class}`logging.Logger`; see also\n",
    "  ['Customised Logger'](./Logger.ipynb))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse `trv_logger`, `parameter_set` and  `binning` created in the\n",
    "['Customised Logger'](./Logger.ipynb), ['Parameter Set'](./Parameters.ipynb)\n",
    "and ['Binnig Scheme'](./Binning.ipynb) tutorials as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:25:57 (+00:00:00) STAT C++] Parameters validated.\n"
     ]
    }
   ],
   "source": [
    "from triumvirate.logger import setup_logger\n",
    "from triumvirate.parameters import ParameterSet\n",
    "from triumvirate.dataobjs import Binning\n",
    "\n",
    "# Demo logger\n",
    "trv_logger = setup_logger()\n",
    "\n",
    "# Demo parameter set\n",
    "try:\n",
    "    parameter_set = ParameterSet(param_filepath=\"parameter_template.yml\")\n",
    "except OSError:\n",
    "    from triumvirate.parameters import fetch_paramset_template\n",
    "\n",
    "    parameter_dict = fetch_paramset_template('dict')\n",
    "\n",
    "    for ax_name in ['x', 'y', 'z']:\n",
    "        parameter_dict['boxsize'][ax_name] = 1000.\n",
    "        parameter_dict['ngrid'][ax_name] = 64\n",
    "\n",
    "    parameter_dict.update({\n",
    "        'catalogue_type': 'sim',\n",
    "        'statistic_type': 'bispec',\n",
    "        'degrees'       : {'ell1': 0, 'ell2': 0, 'ELL': 0},\n",
    "        'range'         : [0.005, 0.105],\n",
    "        'num_bins'      : 10,\n",
    "    })\n",
    "\n",
    "    parameter_set = ParameterSet(param_dict=parameter_dict)\n",
    "\n",
    "# Demo binning\n",
    "binning = Binning('fourier', 'lin', bin_min=0.005, bin_max=0.105, num_bins=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we have used ``nbodykit`` to produce three types of\n",
    "mock catalogues:\n",
    "\n",
    "- The first is a simulation-like log-normal catalogue `catalogue_sim`\n",
    "  in a cubic box of size $L = 1000.\\,h^{-1}\\,\\mathrm{Mpc}$ with number density\n",
    "  $\\bar{n} = 5 \\times 10^{-4} \\,h^3\\,\\mathrm{Mpc}^{-3}$. The input cosmological\n",
    "  parameters are $h = 0.6736, \\Omega_{\\mathrm{CDM},0} = 0.2645, \n",
    "  \\Omega_{\\mathrm{b},0} = 0.04930, A_s = 2.083 \\times 10^{-9}$ and\n",
    "  $n_s = 0.9649$, and the linear power spectrum at redshift $z = 1.$ with\n",
    "  linear tracer bias $b_1 = 2$ is used.\n",
    "\n",
    "- The second is a survey-like catalogue `catalogue_survey` based on\n",
    "  the simulation-like one, with the catalogue cut to the inscribing sphere of\n",
    "  radius $L/2$ inside the cubic box.\n",
    "\n",
    "- The third is a uniform random catalogue `catalogue_rand` with\n",
    "  number density $5 \\bar{n}$ in the same spherical volume as\n",
    "  the survey-like one.\n",
    "\n",
    "Following the ['Particle Catalogue'](./Catalogue.ipynb) tutorial, these\n",
    "catalogues are instantiated as\n",
    "{py:class}`~triumvirate.catalogue.ParticleCatalogue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nbodykit.cosmology import Cosmology\n",
    "\n",
    "# Cosmology, matter power spectrum and bias at given redshift\n",
    "cosmo = Cosmology(\n",
    "    h=0.6736, Omega0_b=0.04930, Omega0_cdm=0.2645, A_s=2.083e-09, n_s=0.9649\n",
    ")\n",
    "redshift = 1.\n",
    "bias = 2.\n",
    "\n",
    "# Catalogue properties\n",
    "density = 5.e-4\n",
    "boxsize = 1000.\n",
    "\n",
    "# Catalogue selectors\n",
    "def cut_to_sphere(coords, boxsize):\n",
    "    return np.less_equal(np.sqrt(np.sum(coords**2, axis=-1)), boxsize/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create simulation-like catalogue, or load if existing.\n",
    "catalogue_sim_filepath = \"mock_catalogue_sim.dat\"\n",
    "\n",
    "try:\n",
    "    catalogue_sim = np.loadtxt(\n",
    "        catalogue_sim_filepath,\n",
    "        dtype=[(axis, np.float64) for axis in ['x', 'y', 'z']]\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    from nbodykit.lab import LinearPower, LogNormalCatalog\n",
    "    powspec = LinearPower(cosmo, redshift)\n",
    "    catalogue_sim = LogNormalCatalog(\n",
    "        powspec, density, boxsize, bias=bias, Nmesh=256, seed=42\n",
    "    )\n",
    "    catalogue_sim['Position'] -= boxsize/2.\n",
    "    np.savetxt(catalogue_sim_filepath, catalogue_sim['Position'].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create survey-like catalogue.\n",
    "try:\n",
    "    catalogue_survey = catalogue_sim[\n",
    "        cut_to_sphere(catalogue_sim['Position'], boxsize).compute()\n",
    "    ]\n",
    "except (IndexError, ValueError):\n",
    "    catalogue_survey = catalogue_sim[\n",
    "        cut_to_sphere(\n",
    "            catalogue_sim[['x', 'y', 'z']]\n",
    "            .view(np.float64).reshape(len(catalogue_sim), 3),\n",
    "            boxsize\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Create random catalogue, or load if existing.\n",
    "catalogue_rand_filepath = \"mock_catalogue_rand.dat\"\n",
    "\n",
    "try:\n",
    "    catalogue_rand = np.loadtxt(\n",
    "        catalogue_rand_filepath,\n",
    "        dtype=[(axis, np.float64) for axis in ['x', 'y', 'z']]\n",
    "    )\n",
    "except FileNotFoundError:\n",
    "    from nbodykit.lab import UniformCatalog\n",
    "    catalogue_rand = UniformCatalog(5*density, boxsize, seed=42)\n",
    "    catalogue_rand['Position'] -= boxsize/2.\n",
    "    catalogue_rand = catalogue_rand[\n",
    "        cut_to_sphere(catalogue_rand['Position'], boxsize).compute()\n",
    "    ]\n",
    "    np.savetxt(catalogue_rand_filepath, catalogue_rand['Position'].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:26:22 (+00:00:24) INFO] Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "[2023-02-26 00:26:22 (+00:00:24) INFO] NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from triumvirate.catalogue import ParticleCatalogue\n",
    "\n",
    "warnings.filterwarnings('ignore', message=\".*'nz' field.*\")\n",
    "\n",
    "catalogue_sim = ParticleCatalogue(\n",
    "    *[catalogue_sim[coord_axis] for coord_axis in ['x', 'y', 'z']]\n",
    ")\n",
    "catalogue_survey = ParticleCatalogue(\n",
    "    *[catalogue_survey[coord_axis] for coord_axis in ['x', 'y', 'z']],\n",
    "    nz=density\n",
    ")\n",
    "catalogue_rand = ParticleCatalogue(\n",
    "    *[catalogue_rand[coord_axis] for coord_axis in ['x', 'y', 'z']],\n",
    "    nz=density\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having specified all the inputs, measurements can be made by simply passing\n",
    "them as arguments to the relevant function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:26:24 (+00:00:26) INFO] Parameter set have been initialised.\n",
      "[2023-02-26 00:26:24 (+00:00:27) STAT C++] Parameters validated.\n",
      "[2023-02-26 00:26:24 (+00:00:26) INFO] Binning has been initialised.\n",
      "[2023-02-26 00:26:25 (+00:00:27) INFO] Lines of sight have been initialised.\n",
      "[2023-02-26 00:26:25 (+00:00:27) INFO] Catalogues have been aligned.\n",
      "[2023-02-26 00:26:25 (+00:00:27) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-26 00:26:25 (+00:00:28) INFO C++] Catalogue loaded: 259444 particles with total sample weight 259444.000 (source=extdata).\n",
      "[2023-02-26 00:26:25 (+00:00:28) INFO C++] Extents of particle coordinates: {'x': (2.438, 998.884), 'y': (0.879, 998.351), 'z': (0.364, 998.843)} (source=extdata).\n",
      "[2023-02-26 00:26:26 (+00:00:29) INFO C++] Catalogue loaded: 1308287 particles with total sample weight 1308287.000 (source=extdata).\n",
      "[2023-02-26 00:26:26 (+00:00:29) INFO C++] Extents of particle coordinates: {'x': (0.604, 999.396), 'y': (0.630, 999.370), 'z': (0.426, 999.574)} (source=extdata).\n",
      "[2023-02-26 00:26:26 (+00:00:29) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-26 00:26:26 (+00:00:29) INFO] Alpha contrast: 1.983082e-01.\n",
      "[2023-02-26 00:26:27 (+00:00:29) INFO] Normalisation factors: 1.541759e+01 (used), 1.550956e+01 (alternative).\n",
      "[2023-02-26 00:26:27 (+00:00:29) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-26 00:26:30 (+00:00:33) STAT C++] Computing bispectrum from paired survey-type catalogues...\n",
      "[2023-02-26 00:26:35 (+00:00:37) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-26 00:26:35 (+00:00:37) STAT C++] Bispectrum term at orders (m1, m2, M) = (0, 0, 0) computed.\n",
      "[2023-02-26 00:26:35 (+00:00:37) STAT C++] ... computed bispectrum from paired survey-type catalogues.\n"
     ]
    }
   ],
   "source": [
    "results = compute_bispec(\n",
    "    catalogue_survey, catalogue_rand,\n",
    "    paramset=parameter_set,\n",
    "    logger=trv_logger\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying lines of sight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case above, the lines of sight are computed automatically, but one could\n",
    "supply external data arrays as replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:26:35 (+00:00:37) INFO] Parameter set have been initialised.\n",
      "[2023-02-26 00:26:35 (+00:00:38) STAT C++] Parameters validated.\n",
      "[2023-02-26 00:26:35 (+00:00:37) INFO] Binning has been initialised.\n",
      "[2023-02-26 00:26:35 (+00:00:37) INFO] Lines of sight have been initialised.\n",
      "[2023-02-26 00:26:35 (+00:00:38) INFO] Catalogues have been aligned.\n",
      "[2023-02-26 00:26:35 (+00:00:38) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-26 00:26:36 (+00:00:38) INFO C++] Catalogue loaded: 259444 particles with total sample weight 259444.000 (source=extdata).\n",
      "[2023-02-26 00:26:36 (+00:00:38) INFO C++] Extents of particle coordinates: {'x': (2.438, 998.884), 'y': (0.879, 998.351), 'z': (0.364, 998.843)} (source=extdata).\n",
      "[2023-02-26 00:26:38 (+00:00:40) INFO C++] Catalogue loaded: 1308287 particles with total sample weight 1308287.000 (source=extdata).\n",
      "[2023-02-26 00:26:38 (+00:00:40) INFO C++] Extents of particle coordinates: {'x': (0.604, 999.396), 'y': (0.630, 999.370), 'z': (0.426, 999.574)} (source=extdata).\n",
      "[2023-02-26 00:26:38 (+00:00:40) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-26 00:26:38 (+00:00:40) INFO] Alpha contrast: 1.983082e-01.\n",
      "[2023-02-26 00:26:38 (+00:00:41) INFO] Normalisation factors: 1.541759e+01 (used), 1.550956e+01 (alternative).\n",
      "[2023-02-26 00:26:38 (+00:00:41) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-26 00:26:44 (+00:00:47) STAT C++] Computing bispectrum from paired survey-type catalogues...\n",
      "[2023-02-26 00:26:50 (+00:00:52) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-26 00:26:50 (+00:00:53) STAT C++] Bispectrum term at orders (m1, m2, M) = (0, 0, 0) computed.\n",
      "[2023-02-26 00:26:50 (+00:00:53) STAT C++] ... computed bispectrum from paired survey-type catalogues.\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "results = compute_bispec(\n",
    "    catalogue_survey, catalogue_rand,\n",
    "    los_data=np.ones((len(catalogue_survey), 3)),\n",
    "    los_rand=np.ones((len(catalogue_rand), 3)),\n",
    "    paramset=parameter_set,\n",
    "    logger=trv_logger\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overriding parameter set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could also override `paramset` (which may be unset as shown in the example\n",
    "below) by passing the relevant keyword arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:26:50 (+00:00:53) INFO] Validating parameters... (entering C++)\n",
      "[2023-02-26 00:26:50 (+00:00:53) INFO] ... validated parameters. (exited C++)\n",
      "[2023-02-26 00:26:50 (+00:00:53) STAT C++] Parameters validated.\n",
      "[2023-02-26 00:26:50 (+00:00:53) INFO] Parameter set have been initialised.\n",
      "[2023-02-26 00:26:50 (+00:00:53) INFO] Binning has been initialised.\n",
      "[2023-02-26 00:26:51 (+00:00:53) INFO] Lines of sight have been initialised.\n",
      "[2023-02-26 00:26:51 (+00:00:53) INFO] Catalogues have been aligned.\n",
      "[2023-02-26 00:26:51 (+00:00:53) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-26 00:26:51 (+00:00:54) INFO C++] Catalogue loaded: 259444 particles with total sample weight 259444.000 (source=extdata).\n",
      "[2023-02-26 00:26:51 (+00:00:54) INFO C++] Extents of particle coordinates: {'x': (2.438, 998.884), 'y': (0.879, 998.351), 'z': (0.364, 998.843)} (source=extdata).\n",
      "[2023-02-26 00:26:53 (+00:00:55) INFO C++] Catalogue loaded: 1308287 particles with total sample weight 1308287.000 (source=extdata).\n",
      "[2023-02-26 00:26:53 (+00:00:55) INFO C++] Extents of particle coordinates: {'x': (0.604, 999.396), 'y': (0.630, 999.370), 'z': (0.426, 999.574)} (source=extdata).\n",
      "[2023-02-26 00:26:53 (+00:00:55) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-26 00:26:53 (+00:00:55) INFO] Alpha contrast: 1.983082e-01.\n",
      "[2023-02-26 00:26:53 (+00:00:55) INFO] Normalisation factors: 1.541759e+01 (used), 1.480691e+01 (alternative).\n",
      "[2023-02-26 00:26:53 (+00:00:55) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-26 00:26:58 (+00:01:01) STAT C++] Computing bispectrum from paired survey-type catalogues...\n",
      "[2023-02-26 00:27:03 (+00:01:06) STAT C++] Bispectrum term at orders (m1, m2, M) = (-1, 1, 0) computed.\n",
      "[2023-02-26 00:27:06 (+00:01:09) STAT C++] Bispectrum term at orders (m1, m2, M) = (0, 0, 0) computed.\n",
      "[2023-02-26 00:27:08 (+00:01:11) STAT C++] Bispectrum term at orders (m1, m2, M) = (1, -1, 0) computed.\n",
      "[2023-02-26 00:27:08 (+00:01:11) STAT C++] ... computed bispectrum from paired survey-type catalogues.\n",
      "[2023-02-26 00:27:08 (+00:01:11) INFO] ... measured clustering statistics. (exited C++)\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "# import warnings\n",
    "warnings.filterwarnings('ignore', message=\".*default values are unchanged.*\")\n",
    "\n",
    "results = compute_bispec(\n",
    "    catalogue_survey, catalogue_rand,\n",
    "    degrees=(1, 1, 0),\n",
    "    binning=binning,\n",
    "    form='full',\n",
    "    idx_bin=5,\n",
    "    sampling_params={\n",
    "        'assignment': 'cic',\n",
    "        'boxsize': [1000.,]*3,\n",
    "        'ngrid': [64,]*3\n",
    "    },\n",
    "    logger=trv_logger\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor differences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other measurement algorithms, the syntax is very similar except for a few\n",
    "minor differences:\n",
    "\n",
    "- For two-point clustering statistics, the argument corresponding to `degrees`\n",
    "  above is `degree` as there is only a single multipole degree. The arguments\n",
    "  `form` and `idx_bin` do not apply.\n",
    "\n",
    "- For global plane-parallel measurements, no random catalogue is required.\n",
    "\n",
    "- For window function measurements, only the random catalogue is required.\n",
    "\n",
    "For full details, please consult the API reference\n",
    "(for {py:mod}`~triumvirate.twopt` and {py:mod}`~triumvirate.threept` modules)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned measurement results are dictionaries containing the\n",
    "raw statistic (key with suffix ``_raw``) without shot noise subtraction,\n",
    "the shot noise (key with suffix ``_shot``), the bin centres for each\n",
    "coordinate dimension (key with suffix ``bin``), the average/effectuve bin\n",
    "coordinates (key with suffix ``eff``), and the number of contributing modes\n",
    "(or analogously pairs/configurations) in each bin (key ``'nmodes'``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bk_raw': array([-6.15401315e+08+5.81529182e-07j,  2.40744325e+08-1.57946198e-07j,\n",
      "       -2.84005114e+08+2.43201247e-07j, -1.06997676e+08+1.07690589e-08j,\n",
      "        1.94789754e+07-1.34613237e-08j,  8.29519632e+07-8.02653370e-09j,\n",
      "       -4.53112276e+06+7.89730988e-08j, -1.06546658e+08-4.30762357e-08j,\n",
      "       -6.84846274e+07-9.60241088e-08j, -1.14891079e+08+1.25639021e-08j]),\n",
      " 'bk_shot': array([ -5212454.33669118-1.09107440e-10j,\n",
      "        -8944908.7000952 -4.90239353e-11j,\n",
      "       -15387868.92505237+8.52076884e-11j,\n",
      "       -17045970.3545955 +4.14547800e-10j,\n",
      "       -21370062.6083337 +5.02576273e-10j,\n",
      "       -13373351.39063533+3.18571967e-10j,\n",
      "       -19646302.2498707 +4.23460712e-10j,\n",
      "       -16373587.0472606 +2.98386134e-10j,\n",
      "       -14739949.24948343+1.12358296e-10j,\n",
      "       -12282473.18290979+5.37997211e-11j]),\n",
      " 'k1bin': array([0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06]),\n",
      " 'k1eff': array([0.06040971, 0.06040971, 0.06040971, 0.06040971, 0.06040971,\n",
      "       0.06040971, 0.06040971, 0.06040971, 0.06040971, 0.06040971]),\n",
      " 'k2bin': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ]),\n",
      " 'k2eff': array([0.01149964, 0.02047114, 0.03052422, 0.04062536, 0.05033379,\n",
      "       0.06040971, 0.07034279, 0.08025683, 0.09014322, 0.10008191]),\n",
      " 'nmodes': array([  56,  194,  488,  812, 1250, 1896, 2426, 3272, 4016, 5138])}\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "from pprint import pprint\n",
    "pprint(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving to files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each algorithmic function for different measurements, if one sets\n",
    "``save='.txt'`` or ``save='.npz'``, the results as a dictionary will be\n",
    "automatically saved to a file in either ``.txt`` or ``.npz`` format.\n",
    "\n",
    "If the `paramset` argument is set to a\n",
    "{py:class}`~triumvirate.parameters.ParameterSet` object, the output directory\n",
    "will be ``paramset['directories']['measurements']`` (an empty output directory\n",
    "path points to the current working directory), and the string\n",
    "``paramset['tags']['output']`` will be appended to the file name before\n",
    "the extension suffix.\n",
    "\n",
    "This is demonstrated below for a global plane-parallel power spectrum\n",
    "measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:27:09 (+00:01:11) INFO] Parameter set have been initialised.\n",
      "[2023-02-26 00:27:09 (+00:01:11) STAT C++] Parameters validated.\n",
      "[2023-02-26 00:27:09 (+00:01:11) STAT C++] Parameters validated.\n",
      "[2023-02-26 00:27:09 (+00:01:11) INFO] Binning has been initialised.\n",
      "[2023-02-26 00:27:09 (+00:01:11) INFO] Catalogue box has been periodised.\n",
      "[2023-02-26 00:27:09 (+00:01:11) INFO] Inserted missing 'nz' field based on particle count and boxsize.\n",
      "[2023-02-26 00:27:09 (+00:01:11) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-26 00:27:09 (+00:01:12) INFO C++] Catalogue loaded: 499214 particles with total sample weight 499214.000 (source=extdata).\n",
      "[2023-02-26 00:27:09 (+00:01:12) INFO C++] Extents of particle coordinates: {'x': (0.000, 1000.000), 'y': (0.000, 999.996), 'z': (0.001, 999.997)} (source=extdata).\n",
      "[2023-02-26 00:27:09 (+00:01:12) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-26 00:27:09 (+00:01:12) INFO] Normalisation factors: 4.012606e-03 (used), 2.859493e-03 (alternative).\n",
      "[2023-02-26 00:27:09 (+00:01:12) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-26 00:27:10 (+00:01:12) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-26 00:27:10 (+00:00:00) STAT C++] Computing power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-26 00:27:10 (+00:00:01) STAT C++] ... computed power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-26 00:27:10 (+00:01:12) INFO] Measurements saved to pk0_demo.txt.\n"
     ]
    }
   ],
   "source": [
    "from triumvirate.twopt import compute_powspec_in_gpp_box\n",
    "\n",
    "# DEMO\n",
    "parameter_set.update(tags={'output': '_demo'})\n",
    "\n",
    "results = compute_powspec_in_gpp_box(\n",
    "    catalogue_sim,\n",
    "    degree=0, paramset=parameter_set,\n",
    "    save='.txt', logger=trv_logger\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the output measurement file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Catalogue source: extdata\n",
      "# Catalogue size: 499214 particles of total sample weight 499214.000\n",
      "# Catalogue particle extents: ([0.000, 1000.000], [0.000, 999.996], [0.001, 999.997])\n",
      "# Box size: (1000.000, 1000.000, 1000.000)\n",
      "# Box alignment: centre\n",
      "# Mesh number: (64, 64, 64)\n",
      "# Mesh assignment and interlacing: tsc, false\n",
      "# Normalisation factor: 4.012605716e-03 (particle-based, used), 2.859492503e-03 (mesh-based, alternative)\n",
      "# [0] k_cen, [1] k_eff, [2] nmodes, [3] Re{pk0_raw}, [4] Im{pk0_raw}, [5] Re{pk0_shot}, [6] Im{pk0_shot}\n",
      "1.000000000e-02\t1.149964290e-02\t        56\t 3.160464459e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "2.000000000e-02\t2.047114034e-02\t       194\t 3.881291749e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "3.000000000e-02\t3.052421724e-02\t       488\t 2.746437063e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "4.000000000e-02\t4.062536317e-02\t       812\t 2.298652996e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "5.000000000e-02\t5.033378732e-02\t      1250\t 2.007483282e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "6.000000000e-02\t6.040971138e-02\t      1896\t 1.820294452e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "7.000000000e-02\t7.034278912e-02\t      2426\t 1.563804996e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "8.000000000e-02\t8.025683499e-02\t      3272\t 1.336728593e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "9.000000000e-02\t9.014322302e-02\t      4016\t 1.174269686e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "1.000000000e-01\t1.000819060e-01\t      5138\t 1.017118890e+04\t 0.000000000e+00\t 2.003148950e+03\t 0.000000000e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "with open(\"pk0_demo.txt\", 'r') as results_file:\n",
    "    print(results_file.read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a header with summary information about the input parameters and\n",
    "data as well as some intermediary results has also been included in the\n",
    "saved file.\n",
    "\n",
    "Analogously, with the ``save='.npz'`` output format, we would have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:27:10 (+00:01:13) INFO] Parameter set have been initialised.\n",
      "[2023-02-26 00:27:10 (+00:01:13) STAT C++] Parameters validated.\n",
      "[2023-02-26 00:27:10 (+00:01:13) INFO] Binning has been initialised.\n",
      "[2023-02-26 00:27:10 (+00:01:13) INFO] Catalogue box has been periodised.\n",
      "[2023-02-26 00:27:10 (+00:01:13) INFO] Preparing catalogue for clustering algorithm... (entering C++)\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO C++] Catalogue loaded: 499214 particles with total sample weight 499214.000 (source=extdata).\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO] ... prepared catalogue for clustering algorithm. (exited C++)\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO C++] Extents of particle coordinates: {'x': (0.000, 1000.000), 'y': (0.000, 999.996), 'z': (0.001, 999.997)} (source=extdata).\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO] Normalisation factors: 4.012606e-03 (used), 2.859493e-03 (alternative).\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO] Measuring clustering statistics... (entering C++)\n",
      "[2023-02-26 00:27:11 (+00:00:02) STAT C++] Computing power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-26 00:27:11 (+00:00:02) STAT C++] ... computed power spectrum from a periodic-box simulation-type catalogue in the global plane-parallel approximation.\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO] ... measured clustering statistics. (exited C++)\n",
      "[2023-02-26 00:27:11 (+00:01:14) INFO] Measurements saved to pk0_demo.npz.\n"
     ]
    }
   ],
   "source": [
    "results = compute_powspec_in_gpp_box(\n",
    "    catalogue_sim,\n",
    "    degree=0, paramset=parameter_set,\n",
    "    save='.npz', logger=trv_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue source: extdata\n",
      "Catalogue size: 499214 particles of total sample weight 499214.000\n",
      "Catalogue particle extents: ([0.000, 1000.000], [0.000, 999.996], [0.001, 999.997])\n",
      "Box size: (1000.000, 1000.000, 1000.000)\n",
      "Box alignment: centre\n",
      "Mesh number: (64, 64, 64)\n",
      "Mesh assignment and interlacing: tsc, false\n",
      "Normalisation factor: 4.012605716e-03 (particle-based, used), 2.859492503e-03 (mesh-based, alternative)\n",
      "[0] k_cen, [1] k_eff, [2] nmodes, [3] Re{pk0_raw}, [4] Im{pk0_raw}, [5] Re{pk0_shot}, [6] Im{pk0_shot}\n"
     ]
    }
   ],
   "source": [
    "# DEMO\n",
    "with np.load(\"pk0_demo.npz\", allow_pickle=True) as results_file:\n",
    "    print(results_file['header'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Hide cell.\n",
    "!rm -r pk0_demo.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmo",
   "language": "python",
   "name": "cosmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a7a1cba6a5ad1075172442d744886e76565787fe92f2df44113e5c941b518c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
